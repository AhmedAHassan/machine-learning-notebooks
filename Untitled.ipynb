{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-ba509a34ba0a>, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-ba509a34ba0a>\"\u001b[0;36m, line \u001b[0;32m31\u001b[0m\n\u001b[0;31m    X=X+np.random.normal(0,0.5,X.shape)%matplotlib inline\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import k-nn classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#view a description of the dataset (uncomment next line to do so)\n",
    "#print(iris.DESCR)\n",
    "\n",
    "#Set X equal to features, Y equal to the targets\n",
    "\n",
    "X=iris.data \n",
    "y=iris.target \n",
    "\n",
    "\n",
    "mySeed=1234567\n",
    "#initialize random seed generator \n",
    "np.random.seed(mySeed)\n",
    "\n",
    "#we add some random noise to our data to make the task more challenging\n",
    "X=X+np.random.normal(0,0.5,X.shape)%matplotlib inline\n",
    "\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import k-nn classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#view a description of the dataset (uncomment next line to do so)\n",
    "#print(iris.DESCR)\n",
    "\n",
    "#Set X equal to features, Y equal to the targets\n",
    "\n",
    "X=iris.data \n",
    "y=iris.target \n",
    "\n",
    "\n",
    "mySeed=1234567\n",
    "#initialize random seed generator \n",
    "np.random.seed(mySeed)\n",
    "\n",
    "#we add some random noise to our data to make the task more challenging\n",
    "X=X+np.random.normal(0,0.5,X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5b92151c9574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m#call your nested crossvalidation function:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0maccuracy_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyNestedCrossVal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'manhattan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmySeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# nested cross validation\n",
    "# X - data / features\n",
    "# y - outputs\n",
    "# foldK - number of folds\n",
    "# nns - list of number of neighbours parameter for validation\n",
    "# dists - list of distances for validation\n",
    "dists=[\"euclidian\", \"manhattan\"]\n",
    "# mySeed - random seed\n",
    "# returns: accuracy over 5 folds (list)\n",
    "\n",
    "\n",
    "def myNestedCrossVal(X,y,foldK,nns,dists,mySeed):\n",
    "    np.random.seed(mySeed)\n",
    "    accuracy_fold=[]\n",
    "\n",
    "    #TASK: use the function np.random.permutation to generate a list of shuffled indices from in the range (0,number of data)\n",
    "    #(you did this already in a task above)\n",
    "    L=list(range(X.shape[0]))\n",
    "    indices = np.random.permutation(L)\n",
    "    #TASK: use the function array_split to split the indices to foldK different bins (here, 5)\n",
    "    #uncomment line below\n",
    "    bins=np.array_split(indices, foldK)\n",
    "    #print(bins)\n",
    "    #no need to worry about this, just checking that everything is OK\n",
    "    assert(foldK==len(bins))\n",
    "    #loop through folds\n",
    "    for i in range(0,foldK):\n",
    "        foldTrain=[] # list to save current indices for training\n",
    "        foldTest=[]  # list to save current indices for testing\n",
    "        foldVal=[]    # list to save current indices for validation\n",
    "        #loop through all bins, take bin i for testing, the next bin for validation, and the rest for training\n",
    "        valBin = (i+1)%foldK\n",
    "        for j in range(0,len(bins)):\n",
    "            if (i == j):\n",
    "                foldTest = bins[i]\n",
    "            elif (j == valBin):\n",
    "                foldVal = bins[valBin]\n",
    "            else:\n",
    "                foldTrain.extend(bins[j])\n",
    "\n",
    "        #print('** Train', len(foldTrain), foldTrain)\n",
    "        #print('** Val', len(foldVal), foldVal)\n",
    "        #print('** Test', len(foldTest), foldTest)\n",
    "        #no need to worry about this, just checking that everything is OK\n",
    "        assert not np.intersect1d(foldTest,foldVal)\n",
    "        assert not np.intersect1d(foldTrain,foldTest)\n",
    "        assert not np.intersect1d(foldTrain,foldVal)\n",
    "        bestDistance='' #save the best distance metric here\n",
    "        bestNN=-1 #save the best number of neighbours here\n",
    "        bestAccuracy=-10 #save the best attained accuracy here (in terms of validation)\n",
    "        # loop through all parameters (one for loop for distances, one for loop for nn)\n",
    "        # train the classifier on current number of neighbours/distance\n",
    "        # obtain results on validation set\n",
    "        # save parameters if results are the best we had\n",
    "        for d in dists:\n",
    "            for nn in nns:\n",
    "                #split to train and test\n",
    "                #define knn classifier, with 5 neighbors and use the euclidian distance\n",
    "                knn=KNeighborsClassifier(n_neighbors=nn, metric=d)\n",
    "                knn.fit(X[foldTrain],y[foldTrain])\n",
    "                y_pred=knn.predict(X[foldVal])\n",
    "                accuracy = accuracy_score(y[foldVal], y_pred)\n",
    "                if accuracy > bestAccuracy:\n",
    "                    bestDistance = d\n",
    "                    bestNN = nn\n",
    "                    bestAccuracy = accuracy\n",
    "\n",
    "        #print('** End of val for this fold, best NN: ', bestNN, 'best Dist: ', bestDistance, '. Accuracy: ', bestAccuracy)\n",
    "        #evaluate on test data:\n",
    "        #extend your training set by including the validation set\n",
    "        #train k-NN classifier on new training set and test on test set\n",
    "        #get performance on fold, save result in accuracy_fold\n",
    "        foldTrain.extend(foldVal)\n",
    "        knn.fit(X[foldTrain],y[foldTrain])\n",
    "        y_=knn.predict(X[foldTest])\n",
    "        accuracy_=accuracy_score(y[foldTest],y_)\n",
    "        accuracy_fold.append(accuracy)\n",
    "        print('==== Final Cross-val on test on this fold with NN', bestNN, 'dist', bestDistance, ' accuracy ',accuracy_score(y[foldTest],y_))\n",
    "\n",
    "    return accuracy_fold;\n",
    "\n",
    "#call your nested crossvalidation function:\n",
    "accuracy_fold=myNestedCrossVal(X,y,5,list(range(1,11)),['euclidean','manhattan'],mySeed)\n",
    "print(accuracy_fold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
